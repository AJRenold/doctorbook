{
 "metadata": {
  "name": "DocBookParse"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get Chapter1.xml and read it into BeautifulSoup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import nltk\n",
      "import pandas as pd\n",
      "\n",
      "ORIGINAL_DRECTORY = '/Users/Desktop/docbookparser/'\n",
      "PATH = 'Chapter1.xml'\n",
      "soup = BeautifulSoup(open(PATH, 'rt').read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Check which tags are in the soup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "book_tags = set([tag.name for tag in soup.findAll(True)])\n",
      "print(book_tags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['ulink', 'surname', 'figure', 'footnote', 'othername', 'primary', 'uri', 'hardware', 'citerefentry', 'manvolnum', 'phrase', 'sidebar', 'tertiary', 'xref', 'sect2', 'para', 'sect1', 'orgname', 'highlights', 'sect1info', 'abbrev', 'filename', 'application', 'emphasis', 'html', 'listitem', 'textobject', 'indexterm', 'chapterinfo', 'firstterm', 'body', 'keywordset', 'blockquote', 'attribution', 'firstname', 'quote', 'symbol', 'literal', 'sect3info', 'citetitle', 'link', 'foreignphrase', 'secondary', 'chapter', 'mediaobject', 'sidebarinfo', 'imagedata', 'keyword', 'glossterm', 'author', 'imageobject', 'personname', 'sect2info', 'refentrytitle', 'action', 'title', 'itemizedlist', 'sect3'])\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get tags and terms and construct a Pandas DataFrame"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "list_for_df = []\n",
      "tags = ['keyword','author','indexterm','orgname','personname','phrase']\n",
      "for tag in tags:\n",
      "    for i in soup.findAll(tag):\n",
      "        if i.string == None:\n",
      "            list_for_df.append({ 'term':\" \".join([ child for child in i.stripped_strings ]), \\\n",
      "                                'tag': tag })\n",
      "        else:\n",
      "            list_for_df.append({ 'term': re.sub('  +','',str(i.string)), 'tag': tag })\n",
      "        \n",
      "df = pd.DataFrame(list_for_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[75:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>tag</th>\n",
        "      <th>term</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>75</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                                 corpus</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>76</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                                  index</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>77</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>             resource description index</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>78</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                  library science index</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>79</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                         language index</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>80</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                intentional arrangement</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>81</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>        concept intentional arrangement</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>82</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                self-organizing systems</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>83</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                            Smith, Adam</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>84</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                        Darwin, Charles</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>85</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>        intentional arrangement defined</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>86</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                   computational agents</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>87</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                 self-organizing system</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>88</th>\n",
        "      <td> indexterm</td>\n",
        "      <td> data structures self-organizing system</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>89</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                                   CERN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>90</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                       Berners-Lee, Tim</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>91</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                                    W3C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>92</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                    computing plain web</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>93</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                   organizing principle</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>94</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>           concept organizing principle</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>95</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                  alphabetical ordering</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>96</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                 chronological ordering</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>97</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>                        digital library</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>98</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>           white space print publishing</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>99</th>\n",
        "      <td> indexterm</td>\n",
        "      <td>         organizing system three tiered</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "          tag                                    term\n",
        "75  indexterm                                  corpus\n",
        "76  indexterm                                   index\n",
        "77  indexterm              resource description index\n",
        "78  indexterm                   library science index\n",
        "79  indexterm                          language index\n",
        "80  indexterm                 intentional arrangement\n",
        "81  indexterm         concept intentional arrangement\n",
        "82  indexterm                 self-organizing systems\n",
        "83  indexterm                             Smith, Adam\n",
        "84  indexterm                         Darwin, Charles\n",
        "85  indexterm         intentional arrangement defined\n",
        "86  indexterm                    computational agents\n",
        "87  indexterm                  self-organizing system\n",
        "88  indexterm  data structures self-organizing system\n",
        "89  indexterm                                    CERN\n",
        "90  indexterm                        Berners-Lee, Tim\n",
        "91  indexterm                                     W3C\n",
        "92  indexterm                     computing plain web\n",
        "93  indexterm                    organizing principle\n",
        "94  indexterm            concept organizing principle\n",
        "95  indexterm                   alphabetical ordering\n",
        "96  indexterm                  chronological ordering\n",
        "97  indexterm                         digital library\n",
        "98  indexterm            white space print publishing\n",
        "99  indexterm          organizing system three tiered"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Function to query DBPedia to find a term's wikipedia url (almost complete)\n",
      "Needs clean up and method to know when a term is not matched"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib2 import urlopen\n",
      "\n",
      "term = 'URL'\n",
      "\n",
      "def check_dbpedia(query):\n",
      "    api = 'http://lookup.dbpedia.org/api/search.asmx/KeywordSearch?MaxHits=10&QueryString='\n",
      "    #api = 'http://lookup.dbpedia.org/api/search.asmx/PrefixSearch?MaxHits=10&QueryString='\n",
      "    response = urlopen(api+query)\n",
      "    soup = BeautifulSoup(response.read())\n",
      "    \n",
      "    uris = []\n",
      "    for result in soup.find_all('result'):\n",
      "        for child in result.children:\n",
      "            try:\n",
      "                if child.name == 'label':\n",
      "                    current_label = child.string\n",
      "                if child.name == 'uri':\n",
      "                    print(current_label,child.name,child.string)\n",
      "                    uris.append([current_label,child.string])\n",
      "            except:\n",
      "                pass\n",
      "    return uris\n",
      "\n",
      "found_term = \"\"\n",
      "URIs = check_dbpedia(term)\n",
      "for uri in URIs:\n",
      "    #print(uri[0].lower())\n",
      "    if uri[0].lower() == term:\n",
      "        found_term = uri[1]\n",
      "        print(\"found!\")\n",
      "        \n",
      "if found_term == \"\":\n",
      "    print(URIs[0][1])\n",
      "    found_term = URIs[0][1]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'Uniform Resource Locator', 'uri', u'http://dbpedia.org/resource/Uniform_Resource_Locator')\n",
        "(u'URL redirection', 'uri', u'http://dbpedia.org/resource/URL_redirection')\n",
        "(u'URL shortening', 'uri', u'http://dbpedia.org/resource/URL_shortening')\n",
        "(u'Search/Retrieve via URL', 'uri', u'http://dbpedia.org/resource/Search/Retrieve_via_URL')\n",
        "(u'Personalized URL', 'uri', u'http://dbpedia.org/resource/Personalized_URL')\n",
        "(u'URL Snooper', 'uri', u'http://dbpedia.org/resource/URL_Snooper')\n",
        "(u'URL With Phred', 'uri', u'http://dbpedia.org/resource/URL_With_Phred')\n",
        "(u'URL normalization', 'uri', u'http://dbpedia.org/resource/URL_normalization')\n",
        "(u'#URL', 'uri', u'http://dbpedia.org/resource/%23URL')\n",
        "(u'#URL encoding', 'uri', u'http://dbpedia.org/resource/%23URL_encoding')\n",
        "http://dbpedia.org/resource/Uniform_Resource_Locator\n"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print found_term"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://dbpedia.org/resource/Uniform_Resource_Locator\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "print found_term\n",
      "\n",
      "def get_wiki_url(term):\n",
      "    \n",
      "    term = term[term.rfind('/'):]\n",
      "    \n",
      "    entity_page = 'http://dbpedia.org/data/{}.json'.format(term)\n",
      "    print(entity_page)\n",
      "    \n",
      "    wiki_type = 'http://xmlns.com/foaf/0.1/primaryTopic'\n",
      "    \n",
      "    response = urlopen(entity_page)\n",
      "    data = json.loads(response.read())\n",
      "    #print(data)\n",
      "    for key,value in data.items():\n",
      "        'http://xmlns.com/foaf/0.1/primaryTopic'\n",
      "        #print(\"key\",value)\n",
      "        if 'http://xmlns.com/foaf/0.1/primaryTopic' in value:\n",
      "            print(key,value)\n",
      "        \n",
      "    #print(data['http://en.wikipedia.org/wiki/Metadata'])\n",
      "    \n",
      "get_wiki_url(found_term)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://dbpedia.org/resource/Uniform_Resource_Locator\n",
        "http://dbpedia.org/data//Uniform_Resource_Locator.json\n",
        "(u'http://en.wikipedia.org/wiki/Uniform_Resource_Locator', {u'http://xmlns.com/foaf/0.1/primaryTopic': [{u'type': u'uri', u'value': u'http://dbpedia.org/resource/Uniform_Resource_Locator'}]})"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Use .apply(check_dpedia) to run function across all terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['wiki_url'] = df['term'].apply(check_dbpedia)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}